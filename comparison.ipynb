{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c354892-7f1d-41c6-bcb7-5e67c7355175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from helpers import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f172bb15-78d3-445b-b748-301045c1ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset\n",
    "data_path = \"data/dataset_to_release_2\"\n",
    "\n",
    "# Load data from the specified dataset path\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d503cefa-679f-4cba-a710-0870cd401a92",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe67ba-966f-4e14-92c5-59ce0de33253",
   "metadata": {},
   "source": [
    "We clean our data with the same manner as in our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6d13c2e-0ea9-4467-a220-ee8a59eb1d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of each array to avoid modifying the original data :\n",
    "x_train_cleaned = x_train.copy()\n",
    "\n",
    "# Calculate the fraction of NaN values for each column\n",
    "nan_fraction_train = np.isnan(x_train_cleaned).mean(axis=0)\n",
    "\n",
    "# Use the mask to filter out columns with more than 80% NaN values\n",
    "mask_null = nan_fraction_train < 0.8\n",
    "x_train_cleaned = x_train_cleaned[:, mask_null]\n",
    "\n",
    "# Identify non-constant columns, columns that have a standard deviation not equal to zero :\n",
    "mask_variance = (np.nanstd(x_train_cleaned, axis=0) != 0.0)\n",
    "\n",
    "# Retain only the non-constant columns in the x_train_copied dataset :\n",
    "x_train_cleaned = x_train_cleaned[:, mask_variance]\n",
    "\n",
    "# For each element in x arrays, if the element is NaN, replace it with the median :\n",
    "x_train_cleaned = np.where(np.isnan(x_train_cleaned), np.nanmedian(x_train_cleaned, axis=0), x_train_cleaned)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "x_train_cleaned = scaler.fit_transform(x_train_cleaned)\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "x_train_set, x_test_set, y_train_set, y_test_set = train_test_split(x_train_cleaned, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e8729-c8fd-4ccf-b68c-184af6128136",
   "metadata": {},
   "source": [
    "# Comparison and interpretation with external libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d357b3f1-2a0e-4131-8d12-0370a0f07414",
   "metadata": {},
   "source": [
    "Let's recall that our Logistic Regression model gave this results (used for the submission) :\n",
    "\n",
    "- **Gamma: 0.25, Max Iters: 1000**\n",
    "- Accuracy: 87.49%\n",
    "- F1 Score: 40.13%\n",
    "- Time Taken: 87.77 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd7be2-4e1c-4957-be2f-5e0c4a82f916",
   "metadata": {},
   "source": [
    "We can to compare our Logistic Regression model with the sklearn Logitic Regression model. Since our data set is too heavy, we have to use the `solver = 'newton-cg'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c8d4907-3a9e-4d95-b31b-e65988698ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.36%\n",
      "F1 score: 17.94%\n",
      "Time Taken: 141.52 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "start_time = time.time()\n",
    "lr = LogisticRegression(solver='newton-cg')\n",
    "lr.fit(x_train_set, y_train_set)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Predicting on the test data\n",
    "pred_test = lr.predict(x_test_set)\n",
    "\n",
    "# Compute accuracy and F1 score\n",
    "accuracy = accuracy_score(y_test_set, pred_test)*100\n",
    "f1 = f1_score(y_test_set, pred_test)*100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}%\")\n",
    "print(f\"Time Taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f87876-2f5d-4d18-8b17-58029a8502cb",
   "metadata": {},
   "source": [
    "It seems that our model is better than the one used in `sklearn` in term of results and performances. \n",
    "\n",
    "Claim : This is probably due to the unbalanced nature of the data, and the fixed decision boundary of 0.5.\n",
    "Therefore we can try some data processing in order to prove our claim. \n",
    "Among them :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6800363-7b95-487e-8aa7-99f5753294a8",
   "metadata": {},
   "source": [
    "- Data Oversampling :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0560cb95-63fb-41e6-a2be-7b8ede4539df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.13%\n",
      "F1 score: 35.95%\n",
      "Time Taken: 552.40 seconds\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "x_train_resampled, y_train_resampled = ros.fit_resample(x_train_set, y_train_set.reshape(-1, 1))\n",
    "\n",
    "# Train the model\n",
    "start_time = time.time()\n",
    "lr = LogisticRegression(solver='newton-cg')\n",
    "lr.fit(x_train_resampled, y_train_resampled)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Predicting on the test data\n",
    "pred_test = lr.predict(x_test_set)\n",
    "\n",
    "# Compute accuracy and F1 score\n",
    "accuracy = accuracy_score(y_test_set, pred_test)*100\n",
    "f1 = f1_score(y_test_set, pred_test)*100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}%\")\n",
    "print(f\"Time Taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76096b8-706b-448d-bed5-e154e42a047c",
   "metadata": {},
   "source": [
    "According to these results, our claim in proved.\n",
    "\n",
    "But even with data resampling, the sklearn Logitic Regression model still has lower results than our Logitic Regression implementation, and takes much more time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632bf782-a288-4c0d-984c-027db719423d",
   "metadata": {},
   "source": [
    "- Applying Class weight :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "650b0362-2c9e-406e-9cb6-d5db9d677529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.88%\n",
      "F1 score: 40.01%\n",
      "Time Taken: 85.47 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "start_time = time.time()\n",
    "lr = LogisticRegression(solver='newton-cg', class_weight={-1: 0.3, 1: 1.0})\n",
    "lr.fit(x_train_set, y_train_set)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Predicting on the test data\n",
    "pred_test = lr.predict(x_test_set)\n",
    "\n",
    "# Compute accuracy and F1 score\n",
    "accuracy = accuracy_score(y_test_set, pred_test)*100\n",
    "f1 = f1_score(y_test_set, pred_test)*100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"F1 score: {f1:.2f}%\")\n",
    "print(f\"Time Taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31b6a4b-652b-4030-b53b-dba60de27763",
   "metadata": {},
   "source": [
    "When applying Class weights, the sklearn Logitic Regression model is **extremely similar** to ours not only in term of results,  but also performances :\n",
    "\n",
    "- Accuracy: 87.49%\n",
    "- F1 Score: 40.13%\n",
    "- Time Taken: 87.77 seconds\n",
    "\n",
    "Therefore, we can conclude that our Logistic Regression Model is quite good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
